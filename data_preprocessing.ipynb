{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import spacy\n",
    "from spacy.lang.id import Indonesian\n",
    "import pandas as pd\n",
    "from wordcloud import wordcloud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>is_gambling_site</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>daftarmasuk hot games slots casino sports arca...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>pemberitahuan pemeliharaan terjadwal sbo virtu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>selama waktu ini sbo virtual sports permainan ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>kami memohon maaf atas ketidaknyamanan yang mu...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>pemeliharaan terjadwal ion slot pada dari am s...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1076</th>\n",
       "      <td>republika tvihramrejabarrejogjaretizenbuku rep...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1077</th>\n",
       "      <td>balibaliexpressradar surabayaradar gresikradar...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1078</th>\n",
       "      <td>dialogis lebih efektifpemerintah mengeklaim di...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1079</th>\n",
       "      <td>var eo subcat const base url const asset url c...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1080</th>\n",
       "      <td>bbc news indonesialangsung ke kontenkategoribe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1081 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   text  is_gambling_site\n",
       "0     daftarmasuk hot games slots casino sports arca...                 1\n",
       "1     pemberitahuan pemeliharaan terjadwal sbo virtu...                 1\n",
       "2     selama waktu ini sbo virtual sports permainan ...                 1\n",
       "3     kami memohon maaf atas ketidaknyamanan yang mu...                 1\n",
       "4     pemeliharaan terjadwal ion slot pada dari am s...                 1\n",
       "...                                                 ...               ...\n",
       "1076  republika tvihramrejabarrejogjaretizenbuku rep...                 0\n",
       "1077  balibaliexpressradar surabayaradar gresikradar...                 0\n",
       "1078  dialogis lebih efektifpemerintah mengeklaim di...                 0\n",
       "1079  var eo subcat const base url const asset url c...                 0\n",
       "1080  bbc news indonesialangsung ke kontenkategoribe...                 0\n",
       "\n",
       "[1081 rows x 2 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv(\"dataset/cleaned_text.csv\")\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = Indonesian()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def removeStopWords(text: str):\n",
    "    \"\"\"\n",
    "    Remove stopwords from the text\n",
    "    \n",
    "        param:\n",
    "            text (str): text that requires stopwords removal\n",
    "        return:\n",
    "            new text after stopwords removal\n",
    "    \"\"\"\n",
    "    \n",
    "    text_doc = nlp(text)\n",
    "    token_list = [token.text for token in text_doc]\n",
    "    filtered_token = [word for word in token_list if nlp.vocab[word].is_stop==False]\n",
    "    \n",
    "    return \" \".join(filtered_token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_doc = nlp(\"jancuk kau di\")\n",
    "token_list = [token.text for token in text_doc]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'str' object has no attribute 'lemma_'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[60], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m word \u001b[38;5;129;01min\u001b[39;00m token_list:\n\u001b[1;32m----> 2\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[43mword\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlemma_\u001b[49m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'str' object has no attribute 'lemma_'"
     ]
    }
   ],
   "source": [
    "for word in token_list:\n",
    "    print(word.lemma_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.blank(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<spacy.lang.en.lemmatizer.EnglishLemmatizer at 0x1e108489280>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nlp.add_pipe(\"lemmatizer\", config={\"mode\": \"lookup\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E955] Can't find table(s) lemma_lookup for language 'en' in spacy-lookups-data. Make sure you have the package installed or provide your own lookup tables if no default lookups are available for your language.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\5002352\\AppData\\Local\\miniconda3\\envs\\gamblesniffer\\lib\\site-packages\\spacy\\language.py:1349\u001b[0m, in \u001b[0;36mLanguage.initialize\u001b[1;34m(self, get_examples, sgd)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         p_settings \u001b[38;5;241m=\u001b[39m I[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponents\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(name, {})\n\u001b[0;32m   1346\u001b[0m         p_settings \u001b[38;5;241m=\u001b[39m validate_init_settings(\n\u001b[0;32m   1347\u001b[0m             proc\u001b[38;5;241m.\u001b[39minitialize, p_settings, section\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponents\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mname\n\u001b[0;32m   1348\u001b[0m         )\n\u001b[1;32m-> 1349\u001b[0m         proc\u001b[38;5;241m.\u001b[39minitialize(get_examples, nlp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mp_settings)\n\u001b[0;32m   1350\u001b[0m pretrain_cfg \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pretrain_cfg:\n",
      "File \u001b[1;32mc:\\Users\\5002352\\AppData\\Local\\miniconda3\\envs\\gamblesniffer\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:159\u001b[0m, in \u001b[0;36mLemmatizer.initialize\u001b[1;34m(self, get_examples, nlp, lookups)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookups \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLemmatizer: loading tables from spacy-lookups-data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 159\u001b[0m     lookups \u001b[38;5;241m=\u001b[39m \u001b[43mload_lookups\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequired_tables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m     optional_lookups \u001b[38;5;241m=\u001b[39m load_lookups(\n\u001b[0;32m    161\u001b[0m         lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mlang, tables\u001b[38;5;241m=\u001b[39moptional_tables, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m optional_lookups\u001b[38;5;241m.\u001b[39mtables:\n",
      "File \u001b[1;32mc:\\Users\\5002352\\AppData\\Local\\miniconda3\\envs\\gamblesniffer\\lib\\site-packages\\spacy\\lookups.py:30\u001b[0m, in \u001b[0;36mload_lookups\u001b[1;34m(lang, tables, strict)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m registry\u001b[38;5;241m.\u001b[39mlookups:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m strict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tables) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 30\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE955\u001b[38;5;241m.\u001b[39mformat(table\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tables), lang\u001b[38;5;241m=\u001b[39mlang))\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lookups\n\u001b[0;32m     32\u001b[0m data \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mlookups\u001b[38;5;241m.\u001b[39mget(lang)\n",
      "\u001b[1;31mValueError\u001b[0m: [E955] Can't find table(s) lemma_lookup for language 'en' in spacy-lookups-data. Make sure you have the package installed or provide your own lookup tables if no default lookups are available for your language."
     ]
    }
   ],
   "source": [
    "nlp.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.lookups import Lookups\n",
    "\n",
    "\n",
    "lookups = Lookups()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(lookups)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Table()"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lookups.add_table(\"en\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E955] Can't find table(s) lemma_lookup for language 'id' in spacy-lookups-data. Make sure you have the package installed or provide your own lookup tables if no default lookups are available for your language.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[61], line 4\u001b[0m\n\u001b[0;32m      2\u001b[0m nlp \u001b[38;5;241m=\u001b[39m spacy\u001b[38;5;241m.\u001b[39mblank(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mid\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m nlp\u001b[38;5;241m.\u001b[39madd_pipe(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlemmatizer\u001b[39m\u001b[38;5;124m\"\u001b[39m, config\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmode\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlookup\u001b[39m\u001b[38;5;124m\"\u001b[39m})\n\u001b[1;32m----> 4\u001b[0m \u001b[43mnlp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minitialize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\5002352\\AppData\\Local\\miniconda3\\envs\\gamblesniffer\\lib\\site-packages\\spacy\\language.py:1349\u001b[0m, in \u001b[0;36mLanguage.initialize\u001b[1;34m(self, get_examples, sgd)\u001b[0m\n\u001b[0;32m   1345\u001b[0m         p_settings \u001b[38;5;241m=\u001b[39m I[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponents\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mget(name, {})\n\u001b[0;32m   1346\u001b[0m         p_settings \u001b[38;5;241m=\u001b[39m validate_init_settings(\n\u001b[0;32m   1347\u001b[0m             proc\u001b[38;5;241m.\u001b[39minitialize, p_settings, section\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcomponents\u001b[39m\u001b[38;5;124m\"\u001b[39m, name\u001b[38;5;241m=\u001b[39mname\n\u001b[0;32m   1348\u001b[0m         )\n\u001b[1;32m-> 1349\u001b[0m         proc\u001b[38;5;241m.\u001b[39minitialize(get_examples, nlp\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mp_settings)\n\u001b[0;32m   1350\u001b[0m pretrain_cfg \u001b[38;5;241m=\u001b[39m config\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpretraining\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m   1351\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m pretrain_cfg:\n",
      "File \u001b[1;32mc:\\Users\\5002352\\AppData\\Local\\miniconda3\\envs\\gamblesniffer\\lib\\site-packages\\spacy\\pipeline\\lemmatizer.py:159\u001b[0m, in \u001b[0;36mLemmatizer.initialize\u001b[1;34m(self, get_examples, nlp, lookups)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lookups \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    158\u001b[0m     logger\u001b[38;5;241m.\u001b[39mdebug(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLemmatizer: loading tables from spacy-lookups-data\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 159\u001b[0m     lookups \u001b[38;5;241m=\u001b[39m \u001b[43mload_lookups\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlang\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mvocab\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlang\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtables\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequired_tables\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    160\u001b[0m     optional_lookups \u001b[38;5;241m=\u001b[39m load_lookups(\n\u001b[0;32m    161\u001b[0m         lang\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mvocab\u001b[38;5;241m.\u001b[39mlang, tables\u001b[38;5;241m=\u001b[39moptional_tables, strict\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     )\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m optional_lookups\u001b[38;5;241m.\u001b[39mtables:\n",
      "File \u001b[1;32mc:\\Users\\5002352\\AppData\\Local\\miniconda3\\envs\\gamblesniffer\\lib\\site-packages\\spacy\\lookups.py:30\u001b[0m, in \u001b[0;36mload_lookups\u001b[1;34m(lang, tables, strict)\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m lang \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m registry\u001b[38;5;241m.\u001b[39mlookups:\n\u001b[0;32m     29\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m strict \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(tables) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m---> 30\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(Errors\u001b[38;5;241m.\u001b[39mE955\u001b[38;5;241m.\u001b[39mformat(table\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(tables), lang\u001b[38;5;241m=\u001b[39mlang))\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lookups\n\u001b[0;32m     32\u001b[0m data \u001b[38;5;241m=\u001b[39m registry\u001b[38;5;241m.\u001b[39mlookups\u001b[38;5;241m.\u001b[39mget(lang)\n",
      "\u001b[1;31mValueError\u001b[0m: [E955] Can't find table(s) lemma_lookup for language 'id' in spacy-lookups-data. Make sure you have the package installed or provide your own lookup tables if no default lookups are available for your language."
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.blank(\"id\")\n",
    "nlp.add_pipe(\"lemmatizer\", config={\"mode\": \"lookup\"})\n",
    "nlp.initialize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gamblesniffer",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
